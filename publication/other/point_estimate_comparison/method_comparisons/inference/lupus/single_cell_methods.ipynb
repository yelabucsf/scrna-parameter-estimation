{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40921d60-4b7a-414d-9189-94ec65917e12",
   "metadata": {},
   "source": [
    "# Single cell methods for cell type comparison in lupus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1935e6f5-9856-4010-9aac-9d1e12293417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import functools\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from patsy import dmatrix, dmatrices \n",
    "import statsmodels.api as sm\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/ssm-user/Github/scrna-parameter-estimation/dist/memento-0.0.9-py3.8.egg')\n",
    "import memento\n",
    "import memento.simulate as simulate\n",
    "\n",
    "data_path = '/data_volume/memento/method_comparison/lupus/'\n",
    "\n",
    "columns = ['logFC', 'PValue', 'FDR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbf047c-1df4-4eda-9531-fe76ce7ee8de",
   "metadata": {},
   "source": [
    "### Read the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbbd061c-f12e-4d60-9b2b-84295f2768ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Your filename has more than two extensions: ['.single_cell', '.10000', '.0', '.h5ad'].\n",
      "Only considering the two last: ['.0', '.h5ad'].\n",
      "WARNING: Your filename has more than two extensions: ['.single_cell', '.10000', '.0', '.h5ad'].\n",
      "Only considering the two last: ['.0', '.h5ad'].\n"
     ]
    }
   ],
   "source": [
    "adata = sc.read(data_path + 'T4_vs_cM.single_cell.10000.0.h5ad')\n",
    "\n",
    "# inds = adata.obs.ind.drop_duplicates().tolist()\n",
    "# cts = adata.obs.cg_cov.drop_duplicates().tolist()\n",
    "\n",
    "# ### Run the t-test\n",
    "\n",
    "# def safe_fdr(x):\n",
    "#     fdr = np.ones(x.shape[0])\n",
    "#     _, fdr[np.isfinite(x)] = fdrcorrection(x[np.isfinite(x)])\n",
    "#     return fdr\n",
    "\n",
    "# ttest_adata = adata.copy()\n",
    "# sc.pp.normalize_total(ttest_adata)\n",
    "# sc.pp.log1p(ttest_adata)\n",
    "\n",
    "# data1 = ttest_adata[ttest_adata.obs['cg_cov'] =='T4'].X.todense()\n",
    "# data2 = ttest_adata[ttest_adata.obs['cg_cov'] =='cM'].X.todense()\n",
    "\n",
    "# statistic, pvalue = stats.ttest_ind(data1, data2, axis=0)\n",
    "\n",
    "# logfc = data1.mean(axis=0) - data2.mean(axis=0)\n",
    "\n",
    "# ttest_result = pd.DataFrame(\n",
    "#     zip(logfc.A1, pvalue, safe_fdr(pvalue)), \n",
    "#     index=ttest_adata.var.index,\n",
    "#     columns=columns)\n",
    "# ttest_result.to_csv(data_path + 'T4_vs_cM.sc.ttest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f36c03c-8704-4111-9ac1-5557ff24798a",
   "metadata": {},
   "source": [
    "### Current top implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d4fb00c-2575-4816-bac4-8ba94e7cfbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_adata = adata.copy()\n",
    "dispersions = pd.read_csv(data_path + 'T4_vs_cM.dispersions.csv', index_col=0)\n",
    "gene_list = dispersions['gene'].tolist()\n",
    "dispersions = dispersions['dispersion'].tolist()\n",
    "\n",
    "def sample_sum(data):\n",
    "    \n",
    "    s = data.sum(axis=0)\n",
    "    return s\n",
    "\n",
    "def scaled_mean_se2(data):\n",
    "    \n",
    "    augmented_data = np.append(data, np.ones((1,data.shape[1])), axis=0)\n",
    "\n",
    "    q=0.07\n",
    "    sf = augmented_data.sum(axis=1)\n",
    "    X = augmented_data/sf.reshape(-1,1)\n",
    "    \n",
    "    naive_v = X.var(axis=0)\n",
    "    naive_m = X.mean(axis=0)\n",
    "    v = naive_v-(1-q)*(X/(sf**2-sf*(1-q)).reshape(-1,1)).mean(axis=0)\n",
    "    variance_contributions = ((1-q)/sf).reshape(-1,1)*naive_m.reshape(1,-1) + v.reshape(1,-1)\n",
    "    m = np.average( X, weights=1/variance_contributions, axis=0)\n",
    "    m[~np.isfinite(m)] = naive_m[~np.isfinite(m)]\n",
    "    \n",
    "    # m = (augmented_data/sf.reshape(-1,1)).mean(axis=0)\n",
    "    # v = (augmented_data/sf.reshape(-1,1)).var(axis=0)\n",
    "    # v = v-(1-q)*(X/(sf**2-sf*(1-q)).reshape(-1,1)).mean(axis=0)\n",
    "    \n",
    "    return m, (v/data.shape[0])\n",
    "\n",
    "scaled_means = []\n",
    "weights = []\n",
    "meta = []\n",
    "totals = []\n",
    "for ind in inds:\n",
    "    for ct in ['cM', 'T4']:\n",
    "        \n",
    "        data = glm_adata[(glm_adata.obs['ind']==ind) & (glm_adata.obs['cg_cov']==ct)].X.toarray()\n",
    "        totals.append(data.sum())\n",
    "        s, se2 = scaled_mean_se2(data)\n",
    "        scaled_means.append(s)\n",
    "        w = np.ones(s.shape[0])\n",
    "        w[se2>0] = 1/se2[se2>0]\n",
    "        weights.append(np.sqrt(1/se2))\n",
    "        meta.append((ind, int(ct=='T4')))\n",
    "scaled_means = pd.DataFrame(np.vstack(scaled_means), columns=glm_adata.var.index)\n",
    "weights = pd.DataFrame(np.vstack(weights), columns=glm_adata.var.index)\n",
    "totals = np.array(totals)\n",
    "meta = pd.DataFrame(meta, columns=['ind', 'ct'])\n",
    "\n",
    "# Filter and re-order by gene_list\n",
    "scaled_means = scaled_means[gene_list]\n",
    "weights = weights[gene_list]\n",
    "\n",
    "# weights = weights / weights.mean(axis=0)\n",
    "\n",
    "design = dmatrix('ct+ind', meta)\n",
    "totals = scaled_means.sum(axis=1).values\n",
    "\n",
    "weighted_mean_glm_results = []\n",
    "for idx in range(len(gene_list)):\n",
    "    model = sm.WLS(\n",
    "        np.log(scaled_means.iloc[:, [idx]]), \n",
    "        design , \n",
    "        weights=weights.iloc[:, idx])\n",
    "    res_model = sm.WLS(\n",
    "        np.log(scaled_means.iloc[:, [idx]]), \n",
    "        design[:, :-1] , \n",
    "        weights=weights.iloc[:, idx])\n",
    "    fit = model.fit()\n",
    "    res_fit = res_model.fit()\n",
    "    pv = stats.chi2.sf(-2*(res_fit.llf - fit.llf), df=res_fit.df_resid-fit.df_resid)\n",
    "    weighted_mean_glm_results.append((fit.params[-1], pv))\n",
    "weighted_mean_glm_results = pd.DataFrame(weighted_mean_glm_results, columns=['logFC', 'PValue'], index=gene_list)\n",
    "_, weighted_mean_glm_results['FDR'] = fdrcorrection(weighted_mean_glm_results['PValue'])\n",
    "\n",
    "weighted_mean_glm_results.to_csv(data_path + 'T4_vs_cM.sc.weighted_mean_wls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6475a465-68f9-4456-a2b4-cd2807647e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_stat, mwu_pval = stats.mannwhitneyu(data1, data2, axis=0)\n",
    "mwu_result = pd.DataFrame(\n",
    "    zip(logfc.A1, mwu_pval, safe_fdr(mwu_pval)), \n",
    "    index=ttest_adata.var.index,\n",
    "    columns=columns)\n",
    "mwu_result.to_csv(data_path + 'T4_vs_cM.sc.mwu.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998a833-8ee1-43f7-b619-0b4d4d0e5b44",
   "metadata": {},
   "source": [
    "### Run weighted regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7beaed-1a62-48cf-896b-2823037fbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_adata = adata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f6b27-4c9b-42e9-a44a-4d482bf523a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mean_estimator(data):\n",
    "    augmented_data = np.append(data, np.ones((1,data.shape[1])), axis=0)\n",
    "    sf = augmented_data.sum(axis=1)\n",
    "    m = (augmented_data/sf.reshape(-1,1)).mean(axis=0)\n",
    "    v = (augmented_data/sf.reshape(-1,1)).var(axis=0)\n",
    "    se = np.sqrt(v/(augmented_data.shape[0]-1))\n",
    "    \n",
    "    return m, se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77bca00-ca12-4f2d-b76d-b0c28bf295eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fe_se(cov):\n",
    "    \"\"\"Get fixed-effect standard error given the precision matrix.\"\"\"\n",
    "    if cov.ndim == 2:\n",
    "        cov = cov[None, :, :]\n",
    "\n",
    "    return np.sqrt(np.diagonal(cov)).T\n",
    "\n",
    "def wls(y, v, X, tau2=0):\n",
    "    \n",
    "    w = 1.0 / (v + tau2)\n",
    "\n",
    "    # Einsum indices: k = studies, p = predictors, i = parallel iterates\n",
    "    wX = np.einsum(\"kp,ki->ipk\", X, w)\n",
    "    cov = wX.dot(X)\n",
    "\n",
    "    # numpy >= 1.8 inverts stacked matrices along the first N - 2 dims, so we\n",
    "    # can vectorize computation along the second dimension (parallel datasets)\n",
    "    precision = np.linalg.pinv(cov).T\n",
    "\n",
    "    pwX = np.einsum(\"ipk,qpi->iqk\", wX, precision)\n",
    "    beta = np.einsum(\"ipk,ik->ip\", pwX, y.T).T\n",
    "    \n",
    "    se = fe_se(precision)\n",
    "    z = beta / se\n",
    "    p = 1 - np.abs(0.5 - stats.norm.cdf(z)) * 2\n",
    "    \n",
    "    return beta, se, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f476191-c7c9-456a-9b87-6ab5c1451ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "variances = []\n",
    "meta = []\n",
    "for ind in inds:\n",
    "    for ct in ['cM', 'T4']:\n",
    "        \n",
    "        data = reg_adata[(reg_adata.obs['ind']==ind) & (reg_adata.obs['cg_cov']==ct)].X.toarray()\n",
    "        m, se = sample_mean_estimator(data)\n",
    "        \n",
    "        means.append(m)\n",
    "        variances.append(np.power(se,2))\n",
    "        meta.append((ind, int(ct=='T4')))\n",
    "means = np.vstack(means)\n",
    "variances = np.vstack(variances)\n",
    "meta = pd.DataFrame(meta, columns=['ind', 'ct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b55cc3-381a-44a3-b863-46c5ca10c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = dmatrix('ct*ind', meta)\n",
    "ct_idx = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2383c8c-992a-4027-86b0-f186ad4cf743",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_list = []\n",
    "pv_list = []\n",
    "for i in range(means.shape[1]):\n",
    "    \n",
    "    b, se, p = wls(means[:,[i]], variances[:,[i]], design)\n",
    "    beta_list.append(b[ct_idx][0])\n",
    "    pv_list.append(p[ct_idx][0])\n",
    "\n",
    "wls_result = pd.DataFrame(zip(beta_list, pv_list,  fdrcorrection(pv_list)[1]  ), columns=columns, index=reg_adata.var.index)\n",
    "wls_result.to_csv(data_path + 'T4_vs_cM.sc.wls.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e51edc-00df-415b-aaef-270c8e48e388",
   "metadata": {
    "tags": []
   },
   "source": [
    "### sum GLM approach with borrowed dispersion parameters - no weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da41efc-845e-420a-91d5-b8f55241ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_adata = adata.copy()\n",
    "dispersions = pd.read_csv(data_path + 'T4_vs_cM.dispersions.csv', index_col=0)\n",
    "gene_list = dispersions['gene'].tolist()\n",
    "dispersions = dispersions['dispersion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7188dd6c-d781-4a8c-9087-446a26dd96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sum(data):\n",
    "    \n",
    "    s = data.sum(axis=0)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3411b6-d31b-4766-880b-feb1b480ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = []\n",
    "meta = []\n",
    "for ind in inds:\n",
    "    for ct in ['cM', 'T4']:\n",
    "        \n",
    "        data = glm_adata[(glm_adata.obs['ind']==ind) & (glm_adata.obs['cg_cov']==ct)].X.toarray()\n",
    "        s = sample_sum(data)\n",
    "        sums.append(s)\n",
    "        meta.append((ind, int(ct=='T4')))\n",
    "sums = pd.DataFrame(np.vstack(sums), columns=glm_adata.var.index)\n",
    "meta = pd.DataFrame(meta, columns=['ind', 'ct'])\n",
    "\n",
    "# Filter and re-order by gene_list\n",
    "sums = sums[gene_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2171b6be-7d31-4788-8b7f-58d1913f5452",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = dmatrix('ct+ind', meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f874d86-2643-419f-87e0-614f1d8ddd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure = sums.sum(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5036a4df-d4e5-4815-9322-9971743ca7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sum_glm_results = []\n",
    "for idx in range(len(gene_list)):\n",
    "    model = sm.GLM(sums.iloc[:, [idx]], design , exposure=exposure,family=sm.families.NegativeBinomial(alpha=dispersions[idx]))\n",
    "    res_model = sm.GLM(sums.iloc[:, [idx]], design[:, :-1] , exposure=exposure,family=sm.families.NegativeBinomial(alpha=dispersions[idx]))\n",
    "    fit = model.fit()\n",
    "    res_fit = res_model.fit()\n",
    "    pv = stats.chi2.sf(-2*(res_fit.llf - fit.llf), df=res_fit.df_resid-fit.df_resid)\n",
    "    sum_glm_results.append((fit.params[-1], pv))\n",
    "sum_glm_results = pd.DataFrame(sum_glm_results, columns=['logFC', 'PValue'], index=gene_list)\n",
    "_, sum_glm_results['FDR'] = fdrcorrection(sum_glm_results['PValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0427d50a-d546-4bab-ad9a-dfc8d8968187",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_glm_results.to_csv(data_path + 'T4_vs_cM.sc.sum_glm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5823eb98-e270-4dcd-a341-66f5d78effe1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### scaled mean GLM approach with borrowed dispersion parameters - no weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6168c783-3b17-4538-a19a-0ca89b439d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_adata = adata.copy()\n",
    "dispersions = pd.read_csv(data_path + 'T4_vs_cM.dispersions.csv', index_col=0)\n",
    "gene_list = dispersions['gene'].tolist()\n",
    "dispersions = dispersions['dispersion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6628ba3-978b-43e8-9769-3b6cb4c2c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sum(data):\n",
    "    \n",
    "    s = data.sum(axis=0)\n",
    "    return s\n",
    "\n",
    "def scaled_mean(data):\n",
    "\n",
    "    sf = data.sum(axis=1)\n",
    "    m = (data/sf.reshape(-1,1)).mean(axis=0)\n",
    "    \n",
    "    return m*data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bd179d-b731-42bd-b5a5-e9d4bd2256f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_means = []\n",
    "meta = []\n",
    "totals = []\n",
    "for ind in inds:\n",
    "    for ct in ['cM', 'T4']:\n",
    "        \n",
    "        data = glm_adata[(glm_adata.obs['ind']==ind) & (glm_adata.obs['cg_cov']==ct)].X.toarray()\n",
    "        totals.append(data.sum())\n",
    "        s = scaled_mean(data)\n",
    "        scaled_means.append(s)\n",
    "        meta.append((ind, int(ct=='T4')))\n",
    "scaled_means = pd.DataFrame(np.vstack(scaled_means), columns=glm_adata.var.index)\n",
    "totals = np.array(totals)\n",
    "meta = pd.DataFrame(meta, columns=['ind', 'ct'])\n",
    "\n",
    "# Filter and re-order by gene_list\n",
    "scaled_means = scaled_means[gene_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde7dbf6-0b84-40ac-966d-6e80869fe7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = dmatrix('ct+ind', meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5332a595-c477-4f15-8ce0-c479b6b00be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = scaled_means.sum(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd17c8-a388-4b11-be23-455d1cec6d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scaled_mean_glm_results = []\n",
    "for idx in range(len(gene_list)):\n",
    "    model = sm.GLM(scaled_means.iloc[:, [idx]], design , exposure=totals,family=sm.families.NegativeBinomial(alpha=dispersions[idx]))\n",
    "    res_model = sm.GLM(scaled_means.iloc[:, [idx]], design[:, :-1] , exposure=totals,family=sm.families.NegativeBinomial(alpha=dispersions[idx]))\n",
    "    fit = model.fit()\n",
    "    res_fit = res_model.fit()\n",
    "    pv = stats.chi2.sf(-2*(res_fit.llf - fit.llf), df=res_fit.df_resid-fit.df_resid)\n",
    "    scaled_mean_glm_results.append((fit.params[-1], pv))\n",
    "scaled_mean_glm_results = pd.DataFrame(scaled_mean_glm_results, columns=['logFC', 'PValue'], index=gene_list)\n",
    "_, scaled_mean_glm_results['FDR'] = fdrcorrection(scaled_mean_glm_results['PValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca0da3a-878a-442a-86a1-5621cc67535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_mean_glm_results.to_csv(data_path + 'T4_vs_cM.sc.scaled_mean_glm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f73c637-f5f4-4b28-a3cb-03d99eeae299",
   "metadata": {
    "tags": []
   },
   "source": [
    "### scaled iv mean GLM approach with borrowed dispersion parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b57e69-183d-4380-aa92-bcd6dfa3513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_adata = adata.copy()\n",
    "dispersions = pd.read_csv(data_path + 'T4_vs_cM.dispersions.csv', index_col=0)\n",
    "gene_list = dispersions['gene'].tolist()\n",
    "dispersions = dispersions['dispersion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0e806-40a2-4dc7-9c0d-6a0bad979bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_iv_mean(data):\n",
    "    q=0.07\n",
    "    augmented_data = data #np.append(data, np.ones((1,data.shape[1])), axis=0)\n",
    "    sf = augmented_data.sum(axis=1)\n",
    "    X = augmented_data/sf.reshape(-1,1)\n",
    "    naive_v = X.var(axis=0)\n",
    "    naive_m = X.mean(axis=0)\n",
    "    v = naive_v-(1-q)*(X/(sf**2-sf*(1-q)).reshape(-1,1)).mean(axis=0)\n",
    "    variance_contributions = ((1-q)/sf).reshape(-1,1)*naive_m.reshape(1,-1) + v.reshape(1,-1)\n",
    "    m = np.average( X, weights=1/variance_contributions, axis=0)\n",
    "    m[~np.isfinite(m)] = naive_m[~np.isfinite(m)]\n",
    "    \n",
    "    return m*augmented_data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca861ca0-6c68-4d19-b127-eebed594d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_iv_means = []\n",
    "meta = []\n",
    "totals = []\n",
    "for ind in inds:\n",
    "    for ct in ['cM', 'T4']:\n",
    "        \n",
    "        data = glm_adata[(glm_adata.obs['ind']==ind) & (glm_adata.obs['cg_cov']==ct)].X.toarray()\n",
    "        totals.append(data.sum())\n",
    "        s = scaled_iv_mean(data)\n",
    "        scaled_iv_means.append(s)\n",
    "        meta.append((ind, int(ct=='T4')))\n",
    "scaled_iv_means = pd.DataFrame(np.vstack(scaled_iv_means), columns=glm_adata.var.index)\n",
    "totals = np.array(totals)\n",
    "meta = pd.DataFrame(meta, columns=['ind', 'ct'])\n",
    "\n",
    "# Filter and re-order by gene_list\n",
    "scaled_iv_means = scaled_iv_means[gene_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a01007-8f5d-485b-a8fe-8943381f4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = dmatrix('ct+ind', meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b2c51-49f8-4785-addf-cde047223425",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = scaled_iv_means.sum(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f49502c-41c4-4853-8475-0eaf9fabd0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scaled_iv_mean_glm_results = []\n",
    "for idx in range(len(gene_list)):\n",
    "    model = sm.GLM(\n",
    "        scaled_iv_means.iloc[:, [idx]].values,\n",
    "        design, \n",
    "        exposure=totals,\n",
    "        family=sm.families.NegativeBinomial(alpha=dispersions[idx]))\n",
    "    res_model = sm.GLM(\n",
    "        scaled_iv_means.iloc[:, [idx]].values,\n",
    "        design[:, :-1] , \n",
    "        exposure=totals,\n",
    "        family=sm.families.NegativeBinomial(alpha=dispersions[idx]))\n",
    "    fit = model.fit()\n",
    "    res_fit = res_model.fit()\n",
    "    pv = stats.chi2.sf(-2*(res_fit.llf - fit.llf), df=res_fit.df_resid-fit.df_resid)\n",
    "    scaled_iv_mean_glm_results.append((fit.params[-1], fit.pvalues[-1]))\n",
    "    # break\n",
    "scaled_iv_mean_glm_results = pd.DataFrame(scaled_iv_mean_glm_results, columns=['logFC', 'PValue'], index=gene_list)\n",
    "_, scaled_iv_mean_glm_results['FDR'] = fdrcorrection(scaled_iv_mean_glm_results['PValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d47c79f-42a1-4ee6-b48a-07d7e91e2193",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_iv_mean_glm_results.to_csv(data_path + 'T4_vs_cM.sc.scaled_iv_mean_glm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e2edd0-d2aa-49fd-84d1-e3a26e49baaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### scaled mean GLM approach with borrowed dispersion parameters - weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d63d104-7da5-420c-807b-fea79f096f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_adata = adata.copy()\n",
    "dispersions = pd.read_csv(data_path + 'T4_vs_cM.dispersions.csv', index_col=0)\n",
    "gene_list = dispersions['gene'].tolist()\n",
    "dispersions = dispersions['dispersion'].tolist()\n",
    "\n",
    "def sample_sum(data):\n",
    "    \n",
    "    s = data.sum(axis=0)\n",
    "    return s\n",
    "\n",
    "def scaled_mean_se2(data):\n",
    "    \n",
    "    augmented_data = np.append(data, np.ones((1,data.shape[1])), axis=0)\n",
    "\n",
    "    q=0.07\n",
    "    sf = augmented_data.sum(axis=1)\n",
    "    X = augmented_data/sf.reshape(-1,1)\n",
    "    \n",
    "    naive_v = X.var(axis=0)\n",
    "    naive_m = X.mean(axis=0)\n",
    "    v = naive_v-(1-q)*(X/(sf**2-sf*(1-q)).reshape(-1,1)).mean(axis=0)\n",
    "    variance_contributions = ((1-q)/sf).reshape(-1,1)*naive_m.reshape(1,-1) + v.reshape(1,-1)\n",
    "    m = np.average( X, weights=1/variance_contributions, axis=0)\n",
    "    m[~np.isfinite(m)] = naive_m[~np.isfinite(m)]\n",
    "    \n",
    "    # m = (augmented_data/sf.reshape(-1,1)).mean(axis=0)\n",
    "    # v = (augmented_data/sf.reshape(-1,1)).var(axis=0)\n",
    "    # v = v-(1-q)*(X/(sf**2-sf*(1-q)).reshape(-1,1)).mean(axis=0)\n",
    "    \n",
    "    return m*data.sum(), (v)*(data.sum()**2),(v/data.shape[0])*(data.sum()**2)\n",
    "\n",
    "scaled_means = []\n",
    "weights = []\n",
    "meta = []\n",
    "totals = []\n",
    "for ind in inds:\n",
    "    for ct in ['cM', 'T4']:\n",
    "        \n",
    "        data = glm_adata[(glm_adata.obs['ind']==ind) & (glm_adata.obs['cg_cov']==ct)].X.toarray()\n",
    "        totals.append(data.sum())\n",
    "        s, v, se2 = scaled_mean_se2(data)\n",
    "        scaled_means.append(s)\n",
    "        w = np.ones(s.shape[0])\n",
    "        w[se2>0] = 1/se2[se2>0]\n",
    "        weights.append(np.sqrt(1/se2))\n",
    "        # weights.append(1/se2)\n",
    "\n",
    "        meta.append((ind, int(ct=='T4')))\n",
    "scaled_means = pd.DataFrame(np.vstack(scaled_means), columns=glm_adata.var.index)\n",
    "weights = pd.DataFrame(np.vstack(weights), columns=glm_adata.var.index)\n",
    "# totals = np.array(totals)\n",
    "totals = (scaled_means).sum(axis=1).values\n",
    "meta = pd.DataFrame(meta, columns=['ind', 'ct'])\n",
    "\n",
    "# Filter and re-order by gene_list\n",
    "scaled_means = scaled_means[gene_list]\n",
    "weights = weights[gene_list]\n",
    "\n",
    "# weights = weights*10\n",
    "# weights = weights / weights.sum(axis=0) * weights.shape[0]\n",
    "# weights[weights.columns] = np.ones(weights.shape)*10\n",
    "# weights = weights /  weights.mean(axis=0)\n",
    "weights = weights / weights.values.mean()\n",
    "design = dmatrix('ct+ind', meta)\n",
    "\n",
    "\n",
    "weighted_mean_glm_results = []\n",
    "for idx in range(len(gene_list)):\n",
    "    model = sm.GLM(\n",
    "        scaled_means.iloc[:, [idx]], \n",
    "        design , \n",
    "        exposure=totals,\n",
    "        var_weights=weights.iloc[:, idx],\n",
    "        family=sm.families.NegativeBinomial(alpha=dispersions[idx]))\n",
    "    res_model = sm.GLM(\n",
    "        scaled_means.iloc[:, [idx]], design[:, :-1] , \n",
    "        exposure=totals,\n",
    "        var_weights=weights.iloc[:, idx],\n",
    "        family=sm.families.NegativeBinomial(alpha=dispersions[idx]))\n",
    "    fit = model.fit()\n",
    "    res_fit = res_model.fit()\n",
    "    pv = stats.chi2.sf(-2*(res_fit.llf - fit.llf), df=res_fit.df_resid-fit.df_resid)\n",
    "    weighted_mean_glm_results.append((fit.params[-1], pv))\n",
    "weighted_mean_glm_results = pd.DataFrame(weighted_mean_glm_results, columns=['logFC', 'PValue'], index=gene_list)\n",
    "_, weighted_mean_glm_results['FDR'] = fdrcorrection(weighted_mean_glm_results['PValue'])\n",
    "\n",
    "weighted_mean_glm_results.to_csv(data_path + 'T4_vs_cM.sc.weighted_mean_glm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc99814-f24d-4fb3-8e05-b7d1ef9b6876",
   "metadata": {
    "tags": []
   },
   "source": [
    "### scaled mean WLS approach with borrowed dispersion parameters - weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "23cc2536-2962-454b-b489-bdaefcd5703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_adata = adata.copy()\n",
    "dispersions = pd.read_csv(data_path + 'T4_vs_cM.dispersions.csv', index_col=0)\n",
    "gene_list = dispersions['gene'].tolist()\n",
    "dispersions = dispersions['dispersion'].tolist()\n",
    "\n",
    "def sample_sum(data):\n",
    "    \n",
    "    s = data.sum(axis=0)\n",
    "    return s\n",
    "\n",
    "def scaled_mean_se2(data):\n",
    "    \n",
    "    augmented_data = np.append(data, np.ones((1,data.shape[1])), axis=0)\n",
    "\n",
    "    q=0.07\n",
    "    sf = augmented_data.sum(axis=1)\n",
    "    X = augmented_data/sf.reshape(-1,1)\n",
    "    \n",
    "    naive_v = X.var(axis=0)\n",
    "    naive_m = X.mean(axis=0)\n",
    "    v = naive_v-(1-q)*(X/(sf**2-sf*(1-q)).reshape(-1,1)).mean(axis=0)\n",
    "    variance_contributions = ((1-q)/sf).reshape(-1,1)*naive_m.reshape(1,-1) + v.reshape(1,-1)\n",
    "    m = np.average( X, weights=1/variance_contributions, axis=0)\n",
    "    m[~np.isfinite(m)] = naive_m[~np.isfinite(m)]\n",
    "    \n",
    "    # m = (augmented_data/sf.reshape(-1,1)).mean(axis=0)\n",
    "    # v = (augmented_data/sf.reshape(-1,1)).var(axis=0)\n",
    "    # v = v-(1-q)*(X/(sf**2-sf*(1-q)).reshape(-1,1)).mean(axis=0)\n",
    "    \n",
    "    return m, (v/data.shape[0])\n",
    "\n",
    "scaled_means = []\n",
    "weights = []\n",
    "meta = []\n",
    "totals = []\n",
    "for ind in inds:\n",
    "    for ct in ['cM', 'T4']:\n",
    "        \n",
    "        data = glm_adata[(glm_adata.obs['ind']==ind) & (glm_adata.obs['cg_cov']==ct)].X.toarray()\n",
    "        totals.append(data.sum())\n",
    "        s, se2 = scaled_mean_se2(data)\n",
    "        scaled_means.append(s)\n",
    "        w = np.ones(s.shape[0])\n",
    "        w[se2>0] = 1/se2[se2>0]\n",
    "        weights.append(np.sqrt(1/se2))\n",
    "        meta.append((ind, int(ct=='T4')))\n",
    "scaled_means = pd.DataFrame(np.vstack(scaled_means), columns=glm_adata.var.index)\n",
    "weights = pd.DataFrame(np.vstack(weights), columns=glm_adata.var.index)\n",
    "totals = np.array(totals)\n",
    "meta = pd.DataFrame(meta, columns=['ind', 'ct'])\n",
    "\n",
    "# Filter and re-order by gene_list\n",
    "scaled_means = scaled_means[gene_list]\n",
    "weights = weights[gene_list]\n",
    "\n",
    "# weights = weights / weights.mean(axis=0)\n",
    "\n",
    "design = dmatrix('ct+ind', meta)\n",
    "totals = scaled_means.sum(axis=1).values\n",
    "\n",
    "weighted_mean_glm_results = []\n",
    "for idx in range(len(gene_list)):\n",
    "    model = sm.WLS(\n",
    "        np.log(scaled_means.iloc[:, [idx]]), \n",
    "        design , \n",
    "        weights=weights.iloc[:, idx])\n",
    "    res_model = sm.WLS(\n",
    "        np.log(scaled_means.iloc[:, [idx]]), \n",
    "        design[:, :-1] , \n",
    "        weights=weights.iloc[:, idx])\n",
    "    fit = model.fit()\n",
    "    res_fit = res_model.fit()\n",
    "    pv = stats.chi2.sf(-2*(res_fit.llf - fit.llf), df=res_fit.df_resid-fit.df_resid)\n",
    "    weighted_mean_glm_results.append((fit.params[-1], pv))\n",
    "weighted_mean_glm_results = pd.DataFrame(weighted_mean_glm_results, columns=['logFC', 'PValue'], index=gene_list)\n",
    "_, weighted_mean_glm_results['FDR'] = fdrcorrection(weighted_mean_glm_results['PValue'])\n",
    "\n",
    "weighted_mean_glm_results.to_csv(data_path + 'T4_vs_cM.sc.weighted_mean_wls.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e77a160-2bff-4568-aa24-306ed3170e70",
   "metadata": {},
   "source": [
    "### Current implementation of memento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "19e018ba-0119-4297-b0b1-f26c5e36d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_adata = adata.copy()\n",
    "dispersions = pd.read_csv(data_path + 'T4_vs_cM.dispersions.csv', index_col=0)\n",
    "gene_list = dispersions['gene'].tolist()\n",
    "dispersions = dispersions['dispersion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "6b3f2ba1-2b6e-4557-86a5-dad85850930e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done  22 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=14)]: Done 172 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=14)]: Done 422 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=14)]: Done 772 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=14)]: Done 1222 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=14)]: Done 1772 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=14)]: Done 2422 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=14)]: Done 3172 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=14)]: Done 4022 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=14)]: Done 4972 tasks      | elapsed:   45.0s\n",
      "[Parallel(n_jobs=14)]: Done 5603 out of 5603 | elapsed:   50.4s finished\n"
     ]
    }
   ],
   "source": [
    "glm_adata.obs['q'] = 0.07\n",
    "memento.setup_memento(glm_adata, q_column='q', filter_mean_thresh=0.001,trim_percent=0.05, shrinkage=0)\n",
    "# de_sim_adata.obs['memento_size_factor'] = de_sim_adata.X.sum(axis=1).A1\n",
    "memento.create_groups(glm_adata, label_columns=['ind', 'cg_cov'])\n",
    "memento.compute_1d_moments(glm_adata, filter_genes=True)\n",
    "\n",
    "meta_df = memento.get_groups(glm_adata)\n",
    "meta_df['ind'] = meta_df['ind'].astype(str)\n",
    "meta_df = pd.get_dummies(meta_df, prefix='', prefix_sep='', drop_first=True)\n",
    "\n",
    "treatment = 1-meta_df[['cM']]\n",
    "covariate = pd.concat([meta_df.iloc[:, :3], meta_df.iloc[:, :3]*treatment.values], axis=1)\n",
    "\n",
    "memento.ht_1d_moments(\n",
    "    glm_adata, \n",
    "    treatment=treatment,\n",
    "    covariate=covariate,\n",
    "    num_boot=5000, \n",
    "    verbose=1,\n",
    "    num_cpus=14,\n",
    "    approx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "52eb7bb3-4f9b-4901-96c4-fe83d1bb8e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "memento_result = memento.get_1d_ht_result(glm_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "0758ee36-a7e6-4897-b0f2-3ce9fcca92f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "memento_result.index = memento_result['gene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "5a3d5ddf-cea5-4081-9cfe-f0599af48164",
   "metadata": {},
   "outputs": [],
   "source": [
    "memento_result['de_fdr'] = memento.util._fdrcorrect(memento_result['de_pval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "92b75e86-da9f-488f-9d32-49ef89033c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "memento_result[['de_coef', 'de_pval', 'de_fdr']].to_csv(data_path + 'T4_vs_cM.sc.memento.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae09f16e-e74f-464b-a8e9-ab7229862984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
