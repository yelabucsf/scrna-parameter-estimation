{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40921d60-4b7a-414d-9189-94ec65917e12",
   "metadata": {},
   "source": [
    "# Single cell methods for cell type comparison in lupus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1935e6f5-9856-4010-9aac-9d1e12293417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import functools\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from patsy import dmatrix, dmatrices \n",
    "import statsmodels.api as sm\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/ssm-user/Github/scrna-parameter-estimation/dist/memento-0.0.9-py3.8.egg')\n",
    "import memento\n",
    "import memento.simulate as simulate\n",
    "\n",
    "data_path = '/data_volume/memento/method_comparison/lupus/'\n",
    "\n",
    "columns = ['logFC', 'PValue', 'FDR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbf047c-1df4-4eda-9531-fe76ce7ee8de",
   "metadata": {},
   "source": [
    "### Read the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbbd061c-f12e-4d60-9b2b-84295f2768ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(data_path + 'T4_vs_cM.single_cell.h5ad')\n",
    "\n",
    "inds = adata.obs.ind.drop_duplicates().tolist()\n",
    "cts = adata.obs.cg_cov.drop_duplicates().tolist()\n",
    "\n",
    "### Run the t-test\n",
    "\n",
    "def safe_fdr(x):\n",
    "    fdr = np.ones(x.shape[0])\n",
    "    _, fdr[np.isfinite(x)] = fdrcorrection(x[np.isfinite(x)])\n",
    "    return fdr\n",
    "\n",
    "ttest_adata = adata.copy()\n",
    "sc.pp.normalize_total(ttest_adata)\n",
    "sc.pp.log1p(ttest_adata)\n",
    "\n",
    "data1 = ttest_adata[ttest_adata.obs['cg_cov'] =='T4'].X.todense()\n",
    "data2 = ttest_adata[ttest_adata.obs['cg_cov'] =='cM'].X.todense()\n",
    "\n",
    "statistic, pvalue = stats.ttest_ind(data1, data2, axis=0)\n",
    "\n",
    "logfc = data1.mean(axis=0) - data2.mean(axis=0)\n",
    "\n",
    "ttest_result = pd.DataFrame(\n",
    "    zip(logfc.A1, pvalue, safe_fdr(pvalue)), \n",
    "    index=ttest_adata.var.index,\n",
    "    columns=columns)\n",
    "ttest_result.to_csv(data_path + 'T4_vs_cM.sc.ttest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc206812-7f45-4eb1-b751-084c92b87b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6475a465-68f9-4456-a2b4-cd2807647e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30041,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mwu_stat, mwu_pval = stats.mannwhitneyu(data1, data2, axis=0)\n",
    "mwu_result = pd.DataFrame(\n",
    "    zip(logfc.A1, mwu_pval, safe_fdr(mwu_pval)), \n",
    "    index=ttest_adata.var.index,\n",
    "    columns=columns)\n",
    "mwu_result.to_csv(data_path + 'T4_vs_cM.sc.mwu.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998a833-8ee1-43f7-b619-0b4d4d0e5b44",
   "metadata": {},
   "source": [
    "### Run weighted regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "7c7beaed-1a62-48cf-896b-2823037fbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_adata = adata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ad7f6b27-4c9b-42e9-a44a-4d482bf523a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mean_estimator(data):\n",
    "    augmented_data = np.append(data, np.ones((1,data.shape[1])), axis=0)\n",
    "    sf = augmented_data.sum(axis=1)\n",
    "    m = (augmented_data/sf.reshape(-1,1)).mean(axis=0)\n",
    "    v = (augmented_data/sf.reshape(-1,1)).var(axis=0)\n",
    "    se = np.sqrt(v/(augmented_data.shape[0]-1))\n",
    "    \n",
    "    return m, se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d77bca00-ca12-4f2d-b76d-b0c28bf295eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fe_se(cov):\n",
    "    \"\"\"Get fixed-effect standard error given the precision matrix.\"\"\"\n",
    "    if cov.ndim == 2:\n",
    "        cov = cov[None, :, :]\n",
    "\n",
    "    return np.sqrt(np.diagonal(cov)).T\n",
    "\n",
    "def wls(y, v, X, tau2=0):\n",
    "    \n",
    "    w = 1.0 / (v + tau2)\n",
    "\n",
    "    # Einsum indices: k = studies, p = predictors, i = parallel iterates\n",
    "    wX = np.einsum(\"kp,ki->ipk\", X, w)\n",
    "    cov = wX.dot(X)\n",
    "\n",
    "    # numpy >= 1.8 inverts stacked matrices along the first N - 2 dims, so we\n",
    "    # can vectorize computation along the second dimension (parallel datasets)\n",
    "    precision = np.linalg.pinv(cov).T\n",
    "\n",
    "    pwX = np.einsum(\"ipk,qpi->iqk\", wX, precision)\n",
    "    beta = np.einsum(\"ipk,ik->ip\", pwX, y.T).T\n",
    "    \n",
    "    se = fe_se(precision)\n",
    "    z = beta / se\n",
    "    p = 1 - np.abs(0.5 - stats.norm.cdf(z)) * 2\n",
    "    \n",
    "    return beta, se, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "4f476191-c7c9-456a-9b87-6ab5c1451ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "variances = []\n",
    "meta = []\n",
    "for ind in inds:\n",
    "    for ct in ['cM', 'T4']:\n",
    "        \n",
    "        data = reg_adata[(reg_adata.obs['ind']==ind) & (reg_adata.obs['cg_cov']==ct)].X.toarray()\n",
    "        m, se = sample_mean_estimator(data)\n",
    "        \n",
    "        means.append(m)\n",
    "        variances.append(np.power(se,2))\n",
    "        meta.append((ind, int(ct=='T4')))\n",
    "means = np.vstack(means)\n",
    "variances = np.vstack(variances)\n",
    "meta = pd.DataFrame(meta, columns=['ind', 'ct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "93b55cc3-381a-44a3-b863-46c5ca10c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = dmatrix('ct*ind', meta)\n",
    "ct_idx = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b2383c8c-992a-4027-86b0-f186ad4cf743",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_list = []\n",
    "pv_list = []\n",
    "for i in range(means.shape[1]):\n",
    "    \n",
    "    b, se, p = wls(means[:,[i]], variances[:,[i]], design)\n",
    "    beta_list.append(b[ct_idx][0])\n",
    "    pv_list.append(p[ct_idx][0])\n",
    "\n",
    "wls_result = pd.DataFrame(zip(beta_list, pv_list,  fdrcorrection(pv_list)[1]  ), columns=columns, index=reg_adata.var.index)\n",
    "wls_result.to_csv(data_path + 'T4_vs_cM.sc.wls.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e51edc-00df-415b-aaef-270c8e48e388",
   "metadata": {
    "tags": []
   },
   "source": [
    "### sum GLM approach with borrowed dispersion parameters - no weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "4da41efc-845e-420a-91d5-b8f55241ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_adata = adata.copy()\n",
    "dispersions = pd.read_csv(data_path + 'T4_vs_cM.dispersions.csv', index_col=0)\n",
    "gene_list = dispersions['gene'].tolist()\n",
    "dispersions = dispersions['dispersion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "7188dd6c-d781-4a8c-9087-446a26dd96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sum(data):\n",
    "    \n",
    "    s = data.sum(axis=0)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "0a3411b6-d31b-4766-880b-feb1b480ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = []\n",
    "meta = []\n",
    "for ind in inds:\n",
    "    for ct in ['cM', 'T4']:\n",
    "        \n",
    "        data = glm_adata[(glm_adata.obs['ind']==ind) & (glm_adata.obs['cg_cov']==ct)].X.toarray()\n",
    "        s = sample_sum(data)\n",
    "        sums.append(s)\n",
    "        meta.append((ind, int(ct=='T4')))\n",
    "sums = pd.DataFrame(np.vstack(sums), columns=glm_adata.var.index)\n",
    "meta = pd.DataFrame(meta, columns=['ind', 'ct'])\n",
    "\n",
    "# Filter and re-order by gene_list\n",
    "sums = sums[gene_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "2171b6be-7d31-4788-8b7f-58d1913f5452",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = dmatrix('ct+ind', meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "2f874d86-2643-419f-87e0-614f1d8ddd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure = sums.sum(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "5036a4df-d4e5-4815-9322-9971743ca7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.1 s, sys: 7.94 ms, total: 17.1 s\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sum_glm_results = []\n",
    "for idx in range(len(gene_list)):\n",
    "    model = sm.GLM(sums.iloc[:, [idx]], design , exposure=exposure,family=sm.families.NegativeBinomial(alpha=dispersions[idx]))\n",
    "    res_model = sm.GLM(sums.iloc[:, [idx]], design[:, :-1] , exposure=exposure,family=sm.families.NegativeBinomial(alpha=dispersions[idx]))\n",
    "    fit = model.fit()\n",
    "    res_fit = res_model.fit()\n",
    "    pv = stats.chi2.sf(-2*(res_fit.llf - fit.llf), df=res_fit.df_resid-fit.df_resid)\n",
    "    sum_glm_results.append((fit.params[-1], pv))\n",
    "sum_glm_results = pd.DataFrame(sum_glm_results, columns=['logFC', 'PValue'], index=gene_list)\n",
    "_, sum_glm_results['FDR'] = fdrcorrection(sum_glm_results['PValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "0427d50a-d546-4bab-ad9a-dfc8d8968187",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_glm_results.to_csv(data_path + 'T4_vs_cM.sc.sum_glm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5823eb98-e270-4dcd-a341-66f5d78effe1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### scaled mean GLM approach with borrowed dispersion parameters - no weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "6168c783-3b17-4538-a19a-0ca89b439d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_adata = adata.copy()\n",
    "dispersions = pd.read_csv(data_path + 'T4_vs_cM.dispersions.csv', index_col=0)\n",
    "gene_list = dispersions['gene'].tolist()\n",
    "dispersions = dispersions['dispersion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "a6628ba3-978b-43e8-9769-3b6cb4c2c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sum(data):\n",
    "    \n",
    "    s = data.sum(axis=0)\n",
    "    return s\n",
    "\n",
    "def scaled_mean(data):\n",
    "\n",
    "    sf = data.sum(axis=1)\n",
    "    m = (data/sf.reshape(-1,1)).mean(axis=0)\n",
    "    \n",
    "    return m*data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c3bd179d-b731-42bd-b5a5-e9d4bd2256f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_means = []\n",
    "meta = []\n",
    "totals = []\n",
    "for ind in inds:\n",
    "    for ct in ['cM', 'T4']:\n",
    "        \n",
    "        data = glm_adata[(glm_adata.obs['ind']==ind) & (glm_adata.obs['cg_cov']==ct)].X.toarray()\n",
    "        totals.append(data.sum())\n",
    "        s = scaled_mean(data)\n",
    "        scaled_means.append(s)\n",
    "        meta.append((ind, int(ct=='T4')))\n",
    "scaled_means = pd.DataFrame(np.vstack(scaled_means), columns=glm_adata.var.index)\n",
    "totals = np.array(totals)\n",
    "meta = pd.DataFrame(meta, columns=['ind', 'ct'])\n",
    "\n",
    "# Filter and re-order by gene_list\n",
    "scaled_means = scaled_means[gene_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "dde7dbf6-0b84-40ac-966d-6e80869fe7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = dmatrix('ct+ind', meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "5332a595-c477-4f15-8ce0-c479b6b00be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = scaled_means.sum(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "adfd17c8-a388-4b11-be23-455d1cec6d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.2 s, sys: 0 ns, total: 17.2 s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scaled_mean_glm_results = []\n",
    "for idx in range(len(gene_list)):\n",
    "    model = sm.GLM(scaled_means.iloc[:, [idx]], design , exposure=totals,family=sm.families.NegativeBinomial(alpha=dispersions[idx]))\n",
    "    res_model = sm.GLM(scaled_means.iloc[:, [idx]], design[:, :-1] , exposure=totals,family=sm.families.NegativeBinomial(alpha=dispersions[idx]))\n",
    "    fit = model.fit()\n",
    "    res_fit = res_model.fit()\n",
    "    pv = stats.chi2.sf(-2*(res_fit.llf - fit.llf), df=res_fit.df_resid-fit.df_resid)\n",
    "    scaled_mean_glm_results.append((fit.params[-1], pv))\n",
    "scaled_mean_glm_results = pd.DataFrame(scaled_mean_glm_results, columns=['logFC', 'PValue'], index=gene_list)\n",
    "_, scaled_mean_glm_results['FDR'] = fdrcorrection(scaled_mean_glm_results['PValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "bca0da3a-878a-442a-86a1-5621cc67535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_mean_glm_results.to_csv(data_path + 'T4_vs_cM.sc.scaled_mean_glm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f73c637-f5f4-4b28-a3cb-03d99eeae299",
   "metadata": {
    "tags": []
   },
   "source": [
    "### scaled iv mean GLM approach with borrowed dispersion parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "c8b57e69-183d-4380-aa92-bcd6dfa3513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_adata = adata.copy()\n",
    "dispersions = pd.read_csv(data_path + 'T4_vs_cM.dispersions.csv', index_col=0)\n",
    "gene_list = dispersions['gene'].tolist()\n",
    "dispersions = dispersions['dispersion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "4ec0e806-40a2-4dc7-9c0d-6a0bad979bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_iv_mean(data):\n",
    "    q=0.07\n",
    "    augmented_data = data #np.append(data, np.ones((1,data.shape[1])), axis=0)\n",
    "    sf = augmented_data.sum(axis=1)\n",
    "    X = augmented_data/sf.reshape(-1,1)\n",
    "    naive_v = X.var(axis=0)\n",
    "    naive_m = X.mean(axis=0)\n",
    "    v = naive_v-(1-q)*(X/(sf**2-sf*(1-q)).reshape(-1,1)).mean(axis=0)\n",
    "    variance_contributions = ((1-q)/sf).reshape(-1,1)*naive_m.reshape(1,-1) + v.reshape(1,-1)\n",
    "    m = np.average( X, weights=1/variance_contributions, axis=0)\n",
    "    m[~np.isfinite(m)] = naive_m[~np.isfinite(m)]\n",
    "    \n",
    "    return m*augmented_data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "ca861ca0-6c68-4d19-b127-eebed594d2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8424/2404292099.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  m = np.average( X, weights=1/variance_contributions, axis=0)\n",
      "/home/ssm-user/anaconda3/envs/single_cell/lib/python3.8/site-packages/numpy/lib/function_base.py:527: RuntimeWarning: invalid value encountered in multiply\n",
      "  avg = np.multiply(a, wgt, dtype=result_dtype).sum(axis)/scl\n"
     ]
    }
   ],
   "source": [
    "scaled_iv_means = []\n",
    "meta = []\n",
    "totals = []\n",
    "for ind in inds:\n",
    "    for ct in ['cM', 'T4']:\n",
    "        \n",
    "        data = glm_adata[(glm_adata.obs['ind']==ind) & (glm_adata.obs['cg_cov']==ct)].X.toarray()\n",
    "        totals.append(data.sum())\n",
    "        s = scaled_iv_mean(data)\n",
    "        scaled_iv_means.append(s)\n",
    "        meta.append((ind, int(ct=='T4')))\n",
    "scaled_iv_means = pd.DataFrame(np.vstack(scaled_iv_means), columns=glm_adata.var.index)\n",
    "totals = np.array(totals)\n",
    "meta = pd.DataFrame(meta, columns=['ind', 'ct'])\n",
    "\n",
    "# Filter and re-order by gene_list\n",
    "scaled_iv_means = scaled_iv_means[gene_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "41a01007-8f5d-485b-a8fe-8943381f4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = dmatrix('ct+ind', meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "a24b2c51-49f8-4785-addf-cde047223425",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = scaled_iv_means.sum(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "5f49502c-41c4-4853-8475-0eaf9fabd0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.3 s, sys: 0 ns, total: 16.3 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scaled_iv_mean_glm_results = []\n",
    "for idx in range(len(gene_list)):\n",
    "    model = sm.GLM(\n",
    "        scaled_iv_means.iloc[:, [idx]].values,\n",
    "        design, \n",
    "        exposure=totals,\n",
    "        family=sm.families.NegativeBinomial(alpha=dispersions[idx]))\n",
    "    res_model = sm.GLM(\n",
    "        scaled_iv_means.iloc[:, [idx]].values,\n",
    "        design[:, :-1] , \n",
    "        exposure=totals,\n",
    "        family=sm.families.NegativeBinomial(alpha=dispersions[idx]))\n",
    "    fit = model.fit()\n",
    "    res_fit = res_model.fit()\n",
    "    pv = stats.chi2.sf(-2*(res_fit.llf - fit.llf), df=res_fit.df_resid-fit.df_resid)\n",
    "    scaled_iv_mean_glm_results.append((fit.params[-1], fit.pvalues[-1]))\n",
    "    # break\n",
    "scaled_iv_mean_glm_results = pd.DataFrame(scaled_iv_mean_glm_results, columns=['logFC', 'PValue'], index=gene_list)\n",
    "_, scaled_iv_mean_glm_results['FDR'] = fdrcorrection(scaled_iv_mean_glm_results['PValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "0d47c79f-42a1-4ee6-b48a-07d7e91e2193",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_iv_mean_glm_results.to_csv(data_path + 'T4_vs_cM.sc.scaled_iv_mean_glm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e2edd0-d2aa-49fd-84d1-e3a26e49baaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### scaled mean GLM approach with borrowed dispersion parameters - weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0d63d104-7da5-420c-807b-fea79f096f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_adata = adata.copy()\n",
    "dispersions = pd.read_csv(data_path + 'T4_vs_cM.dispersions.csv', index_col=0)\n",
    "gene_list = dispersions['gene'].tolist()\n",
    "dispersions = dispersions['dispersion'].tolist()\n",
    "\n",
    "def sample_sum(data):\n",
    "    \n",
    "    s = data.sum(axis=0)\n",
    "    return s\n",
    "\n",
    "def scaled_mean_se2(data):\n",
    "    \n",
    "    augmented_data = np.append(data, np.ones((1,data.shape[1])), axis=0)\n",
    "\n",
    "    q=0.07\n",
    "    sf = augmented_data.sum(axis=1)\n",
    "    X = augmented_data/sf.reshape(-1,1)\n",
    "    \n",
    "    naive_v = X.var(axis=0)\n",
    "    naive_m = X.mean(axis=0)\n",
    "    v = naive_v-(1-q)*(X/(sf**2-sf*(1-q)).reshape(-1,1)).mean(axis=0)\n",
    "    variance_contributions = ((1-q)/sf).reshape(-1,1)*naive_m.reshape(1,-1) + v.reshape(1,-1)\n",
    "    m = np.average( X, weights=1/variance_contributions, axis=0)\n",
    "    m[~np.isfinite(m)] = naive_m[~np.isfinite(m)]\n",
    "    \n",
    "    # m = (augmented_data/sf.reshape(-1,1)).mean(axis=0)\n",
    "    # v = (augmented_data/sf.reshape(-1,1)).var(axis=0)\n",
    "    # v = v-(1-q)*(X/(sf**2-sf*(1-q)).reshape(-1,1)).mean(axis=0)\n",
    "    \n",
    "    return m*data.sum(), (v)*(data.sum()**2),(v/data.shape[0])*(data.sum()**2)\n",
    "\n",
    "scaled_means = []\n",
    "weights = []\n",
    "meta = []\n",
    "totals = []\n",
    "for ind in inds:\n",
    "    for ct in ['cM', 'T4']:\n",
    "        \n",
    "        data = glm_adata[(glm_adata.obs['ind']==ind) & (glm_adata.obs['cg_cov']==ct)].X.toarray()\n",
    "        totals.append(data.sum())\n",
    "        s, v, se2 = scaled_mean_se2(data)\n",
    "        scaled_means.append(s)\n",
    "        w = np.ones(s.shape[0])\n",
    "        w[se2>0] = 1/se2[se2>0]\n",
    "        weights.append(np.sqrt(1/se2))\n",
    "        # weights.append(1/se2)\n",
    "\n",
    "        meta.append((ind, int(ct=='T4')))\n",
    "scaled_means = pd.DataFrame(np.vstack(scaled_means), columns=glm_adata.var.index)\n",
    "weights = pd.DataFrame(np.vstack(weights), columns=glm_adata.var.index)\n",
    "# totals = np.array(totals)\n",
    "totals = (scaled_means).sum(axis=1).values\n",
    "meta = pd.DataFrame(meta, columns=['ind', 'ct'])\n",
    "\n",
    "# Filter and re-order by gene_list\n",
    "scaled_means = scaled_means[gene_list]\n",
    "weights = weights[gene_list]\n",
    "\n",
    "# weights = weights*10\n",
    "# weights = weights / weights.sum(axis=0) * weights.shape[0]\n",
    "# weights[weights.columns] = np.ones(weights.shape)*10\n",
    "# weights = weights /  weights.mean(axis=0)\n",
    "weights = weights / weights.values.mean()\n",
    "design = dmatrix('ct+ind', meta)\n",
    "\n",
    "\n",
    "weighted_mean_glm_results = []\n",
    "for idx in range(len(gene_list)):\n",
    "    model = sm.GLM(\n",
    "        scaled_means.iloc[:, [idx]], \n",
    "        design , \n",
    "        exposure=totals,\n",
    "        var_weights=weights.iloc[:, idx],\n",
    "        family=sm.families.NegativeBinomial(alpha=dispersions[idx]))\n",
    "    res_model = sm.GLM(\n",
    "        scaled_means.iloc[:, [idx]], design[:, :-1] , \n",
    "        exposure=totals,\n",
    "        var_weights=weights.iloc[:, idx],\n",
    "        family=sm.families.NegativeBinomial(alpha=dispersions[idx]))\n",
    "    fit = model.fit()\n",
    "    res_fit = res_model.fit()\n",
    "    pv = stats.chi2.sf(-2*(res_fit.llf - fit.llf), df=res_fit.df_resid-fit.df_resid)\n",
    "    weighted_mean_glm_results.append((fit.params[-1], pv))\n",
    "weighted_mean_glm_results = pd.DataFrame(weighted_mean_glm_results, columns=['logFC', 'PValue'], index=gene_list)\n",
    "_, weighted_mean_glm_results['FDR'] = fdrcorrection(weighted_mean_glm_results['PValue'])\n",
    "\n",
    "weighted_mean_glm_results.to_csv(data_path + 'T4_vs_cM.sc.weighted_mean_glm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc99814-f24d-4fb3-8e05-b7d1ef9b6876",
   "metadata": {
    "tags": []
   },
   "source": [
    "### scaled mean WLS approach with borrowed dispersion parameters - weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "23cc2536-2962-454b-b489-bdaefcd5703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_adata = adata.copy()\n",
    "dispersions = pd.read_csv(data_path + 'T4_vs_cM.dispersions.csv', index_col=0)\n",
    "gene_list = dispersions['gene'].tolist()\n",
    "dispersions = dispersions['dispersion'].tolist()\n",
    "\n",
    "def sample_sum(data):\n",
    "    \n",
    "    s = data.sum(axis=0)\n",
    "    return s\n",
    "\n",
    "def scaled_mean_se2(data):\n",
    "    \n",
    "    augmented_data = np.append(data, np.ones((1,data.shape[1])), axis=0)\n",
    "\n",
    "    q=0.07\n",
    "    sf = augmented_data.sum(axis=1)\n",
    "    X = augmented_data/sf.reshape(-1,1)\n",
    "    \n",
    "    naive_v = X.var(axis=0)\n",
    "    naive_m = X.mean(axis=0)\n",
    "    v = naive_v-(1-q)*(X/(sf**2-sf*(1-q)).reshape(-1,1)).mean(axis=0)\n",
    "    variance_contributions = ((1-q)/sf).reshape(-1,1)*naive_m.reshape(1,-1) + v.reshape(1,-1)\n",
    "    m = np.average( X, weights=1/variance_contributions, axis=0)\n",
    "    m[~np.isfinite(m)] = naive_m[~np.isfinite(m)]\n",
    "    \n",
    "    # m = (augmented_data/sf.reshape(-1,1)).mean(axis=0)\n",
    "    # v = (augmented_data/sf.reshape(-1,1)).var(axis=0)\n",
    "    # v = v-(1-q)*(X/(sf**2-sf*(1-q)).reshape(-1,1)).mean(axis=0)\n",
    "    \n",
    "    return m, (v/data.shape[0])\n",
    "\n",
    "scaled_means = []\n",
    "weights = []\n",
    "meta = []\n",
    "totals = []\n",
    "for ind in inds:\n",
    "    for ct in ['cM', 'T4']:\n",
    "        \n",
    "        data = glm_adata[(glm_adata.obs['ind']==ind) & (glm_adata.obs['cg_cov']==ct)].X.toarray()\n",
    "        totals.append(data.sum())\n",
    "        s, se2 = scaled_mean_se2(data)\n",
    "        scaled_means.append(s)\n",
    "        w = np.ones(s.shape[0])\n",
    "        w[se2>0] = 1/se2[se2>0]\n",
    "        weights.append(np.sqrt(1/se2))\n",
    "        meta.append((ind, int(ct=='T4')))\n",
    "scaled_means = pd.DataFrame(np.vstack(scaled_means), columns=glm_adata.var.index)\n",
    "weights = pd.DataFrame(np.vstack(weights), columns=glm_adata.var.index)\n",
    "totals = np.array(totals)\n",
    "meta = pd.DataFrame(meta, columns=['ind', 'ct'])\n",
    "\n",
    "# Filter and re-order by gene_list\n",
    "scaled_means = scaled_means[gene_list]\n",
    "weights = weights[gene_list]\n",
    "\n",
    "# weights = weights / weights.mean(axis=0)\n",
    "\n",
    "design = dmatrix('ct+ind', meta)\n",
    "totals = scaled_means.sum(axis=1).values\n",
    "\n",
    "weighted_mean_glm_results = []\n",
    "for idx in range(len(gene_list)):\n",
    "    model = sm.WLS(\n",
    "        np.log(scaled_means.iloc[:, [idx]]), \n",
    "        design , \n",
    "        weights=weights.iloc[:, idx])\n",
    "    res_model = sm.WLS(\n",
    "        np.log(scaled_means.iloc[:, [idx]]), \n",
    "        design[:, :-1] , \n",
    "        weights=weights.iloc[:, idx])\n",
    "    fit = model.fit()\n",
    "    res_fit = res_model.fit()\n",
    "    pv = stats.chi2.sf(-2*(res_fit.llf - fit.llf), df=res_fit.df_resid-fit.df_resid)\n",
    "    weighted_mean_glm_results.append((fit.params[-1], pv))\n",
    "weighted_mean_glm_results = pd.DataFrame(weighted_mean_glm_results, columns=['logFC', 'PValue'], index=gene_list)\n",
    "_, weighted_mean_glm_results['FDR'] = fdrcorrection(weighted_mean_glm_results['PValue'])\n",
    "\n",
    "weighted_mean_glm_results.to_csv(data_path + 'T4_vs_cM.sc.weighted_mean_wls.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e77a160-2bff-4568-aa24-306ed3170e70",
   "metadata": {},
   "source": [
    "### Current implementation of memento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "19e018ba-0119-4297-b0b1-f26c5e36d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_adata = adata.copy()\n",
    "dispersions = pd.read_csv(data_path + 'T4_vs_cM.dispersions.csv', index_col=0)\n",
    "gene_list = dispersions['gene'].tolist()\n",
    "dispersions = dispersions['dispersion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "6b3f2ba1-2b6e-4557-86a5-dad85850930e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done  22 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=14)]: Done 172 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=14)]: Done 422 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=14)]: Done 772 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=14)]: Done 1222 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=14)]: Done 1772 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=14)]: Done 2422 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=14)]: Done 3172 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=14)]: Done 4022 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=14)]: Done 4972 tasks      | elapsed:   45.0s\n",
      "[Parallel(n_jobs=14)]: Done 5603 out of 5603 | elapsed:   50.4s finished\n"
     ]
    }
   ],
   "source": [
    "glm_adata.obs['q'] = 0.07\n",
    "memento.setup_memento(glm_adata, q_column='q', filter_mean_thresh=0.001,trim_percent=0.05, shrinkage=0)\n",
    "# de_sim_adata.obs['memento_size_factor'] = de_sim_adata.X.sum(axis=1).A1\n",
    "memento.create_groups(glm_adata, label_columns=['ind', 'cg_cov'])\n",
    "memento.compute_1d_moments(glm_adata, filter_genes=True)\n",
    "\n",
    "meta_df = memento.get_groups(glm_adata)\n",
    "meta_df['ind'] = meta_df['ind'].astype(str)\n",
    "meta_df = pd.get_dummies(meta_df, prefix='', prefix_sep='', drop_first=True)\n",
    "\n",
    "treatment = 1-meta_df[['cM']]\n",
    "covariate = pd.concat([meta_df.iloc[:, :3], meta_df.iloc[:, :3]*treatment.values], axis=1)\n",
    "\n",
    "memento.ht_1d_moments(\n",
    "    glm_adata, \n",
    "    treatment=treatment,\n",
    "    covariate=covariate,\n",
    "    num_boot=5000, \n",
    "    verbose=1,\n",
    "    num_cpus=14,\n",
    "    approx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "52eb7bb3-4f9b-4901-96c4-fe83d1bb8e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "memento_result = memento.get_1d_ht_result(glm_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "0758ee36-a7e6-4897-b0f2-3ce9fcca92f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "memento_result.index = memento_result['gene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "5a3d5ddf-cea5-4081-9cfe-f0599af48164",
   "metadata": {},
   "outputs": [],
   "source": [
    "memento_result['de_fdr'] = memento.util._fdrcorrect(memento_result['de_pval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "92b75e86-da9f-488f-9d32-49ef89033c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "memento_result[['de_coef', 'de_pval', 'de_fdr']].to_csv(data_path + 'T4_vs_cM.sc.memento.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46b553-6608-4db5-a43d-609fcc7db95e",
   "metadata": {},
   "source": [
    "### GLM test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d58e2cff-12b4-4d1e-901b-4e6828bca51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([0, 0, 0, 0.5, 1, 1]).reshape(-1,1)\n",
    "X = sm.add_constant(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5e6ddfd4-f29f-4061-8b70-43b31c939456",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.array([2, 5]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d0b8f7b5-3f35-455f-90b2-3f2e84c210c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = stats.poisson.rvs(np.exp(X@beta))\n",
    "logdata = np.log(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a3da83bb-697c-43aa-b99d-ffbf727bfa67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>     6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>     4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>    <td>NegativeBinomial</td> <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -29.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 16 Mar 2023</td> <th>  Deviance:          </th> <td> 0.53317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>00:04:30</td>     <th>  Pearson chi2:      </th>  <td> 0.474</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>7</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.9988</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    2.2746</td> <td>    0.430</td> <td>    5.292</td> <td> 0.000</td> <td>    1.432</td> <td>    3.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    4.6937</td> <td>    0.671</td> <td>    6.994</td> <td> 0.000</td> <td>    3.378</td> <td>    6.009</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                    6\n",
       "Model:                            GLM   Df Residuals:                        4\n",
       "Model Family:        NegativeBinomial   Df Model:                            1\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -29.498\n",
       "Date:                Thu, 16 Mar 2023   Deviance:                      0.53317\n",
       "Time:                        00:04:30   Pearson chi2:                    0.474\n",
       "No. Iterations:                     7   Pseudo R-squ. (CS):             0.9988\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          2.2746      0.430      5.292      0.000       1.432       3.117\n",
       "x1             4.6937      0.671      6.994      0.000       3.378       6.009\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.GLM(data, X, family=sm.families.NegativeBinomial(alpha=0.5)).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9c02b617-49e5-43e5-bf49-fff4030c0511",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([0.3, 0.6, 0.2, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a38813ff-8af9-4d29-925a-52b49ba91537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssm-user/anaconda3/envs/single_cell/lib/python3.8/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>WLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>WLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>4.321e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 16 Mar 2023</td> <th>  Prob (F-statistic):</th> <td>2.31e-07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:03:44</td>     <th>  Log-Likelihood:    </th> <td>  19.085</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>     4</td>      <th>  AIC:               </th> <td>  -34.17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     2</td>      <th>  BIC:               </th> <td>  -35.40</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    1.3863</td> <td>    0.002</td> <td>  696.567</td> <td> 0.000</td> <td>    1.378</td> <td>    1.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    5.5781</td> <td>    0.003</td> <td> 2078.618</td> <td> 0.000</td> <td>    5.567</td> <td>    5.590</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>   nan</td> <th>  Durbin-Watson:     </th> <td>   2.590</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td>   nan</td> <th>  Jarque-Bera (JB):  </th> <td>   0.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.694</td> <th>  Prob(JB):          </th> <td>   0.797</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.110</td> <th>  Cond. No.          </th> <td>    2.75</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            WLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       1.000\n",
       "Model:                            WLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 4.321e+06\n",
       "Date:                Thu, 16 Mar 2023   Prob (F-statistic):           2.31e-07\n",
       "Time:                        00:03:44   Log-Likelihood:                 19.085\n",
       "No. Observations:                   4   AIC:                            -34.17\n",
       "Df Residuals:                       2   BIC:                            -35.40\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.3863      0.002    696.567      0.000       1.378       1.395\n",
       "x1             5.5781      0.003   2078.618      0.000       5.567       5.590\n",
       "==============================================================================\n",
       "Omnibus:                          nan   Durbin-Watson:                   2.590\n",
       "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.453\n",
       "Skew:                           0.694   Prob(JB):                        0.797\n",
       "Kurtosis:                       2.110   Cond. No.                         2.75\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.WLS(logdata, X, weights=weights).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4593fa-1b1c-4af8-a1cf-a1d1f706b909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae09f16e-e74f-464b-a8e9-ab7229862984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
